{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit6102001/PongGame/blob/main/handwrittendigit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45841af-9e9c-4fc6-9d25-ef9605b0117b",
      "metadata": {
        "id": "b45841af-9e9c-4fc6-9d25-ef9605b0117b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90107255-8cc0-451d-a428-ead2470b5abb",
      "metadata": {
        "id": "90107255-8cc0-451d-a428-ead2470b5abb"
      },
      "outputs": [],
      "source": [
        "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e94304-c055-44d0-8001-96f0abdcbed0",
      "metadata": {
        "id": "20e94304-c055-44d0-8001-96f0abdcbed0",
        "outputId": "6074b729-0287-4d88-b383-f44d145c2f23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c34410-336f-429d-a6da-185b71c85312",
      "metadata": {
        "id": "b4c34410-336f-429d-a6da-185b71c85312",
        "outputId": "4b62f189-9d8c-4ceb-efc7-66f7d9b86a8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe45d5b-a9fc-4a6b-95b6-fe3a7337a1c1",
      "metadata": {
        "id": "abe45d5b-a9fc-4a6b-95b6-fe3a7337a1c1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575c0644-ff1b-46ef-863a-0f7591fc1bfc",
      "metadata": {
        "id": "575c0644-ff1b-46ef-863a-0f7591fc1bfc",
        "outputId": "185d9fa7-242c-405d-bc2a-0b9a1156ac2e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[50],cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5a95b4-7542-42c8-af78-164bf4509d5b",
      "metadata": {
        "id": "dd5a95b4-7542-42c8-af78-164bf4509d5b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2ba55d-0c04-47dc-8b14-c2a992e1877e",
      "metadata": {
        "id": "8e2ba55d-0c04-47dc-8b14-c2a992e1877e"
      },
      "outputs": [],
      "source": [
        "X_train=X_train/255.0\n",
        "X_test=X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a5f65d-87e6-408a-afc2-a0de659bbe3c",
      "metadata": {
        "id": "c9a5f65d-87e6-408a-afc2-a0de659bbe3c",
        "outputId": "520fd6a1-4601-40b0-a0e9-ce8f3fb1c0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "600/600 [==============================] - 2s 2ms/step - loss: 0.3014 - accuracy: 0.9122\n",
            "Epoch 2/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.9659\n",
            "Epoch 3/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9755\n",
            "Epoch 4/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9816\n",
            "Epoch 5/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0474 - accuracy: 0.9852\n",
            "Epoch 6/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0371 - accuracy: 0.9882\n",
            "Epoch 7/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9896\n",
            "Epoch 8/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9916\n",
            "Epoch 9/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9921\n",
            "Epoch 10/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9938\n",
            "Epoch 11/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9936\n",
            "Epoch 12/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9945\n",
            "Epoch 13/200\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9960\n",
            "Epoch 14/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9958\n",
            "Epoch 15/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9940\n",
            "Epoch 16/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9964\n",
            "Epoch 17/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9967\n",
            "Epoch 18/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0121 - accuracy: 0.9961\n",
            "Epoch 19/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9967\n",
            "Epoch 20/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0131 - accuracy: 0.9958\n",
            "Epoch 21/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9973\n",
            "Epoch 22/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9969\n",
            "Epoch 23/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9968\n",
            "Epoch 24/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9981\n",
            "Epoch 25/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0106 - accuracy: 0.9966\n",
            "Epoch 26/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9977\n",
            "Epoch 27/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9973\n",
            "Epoch 28/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 29/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9968\n",
            "Epoch 30/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9979\n",
            "Epoch 31/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 32/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9969\n",
            "Epoch 33/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9978\n",
            "Epoch 34/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 35/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9990\n",
            "Epoch 36/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 37/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9974\n",
            "Epoch 38/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9972\n",
            "Epoch 39/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Epoch 40/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 41/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9969\n",
            "Epoch 42/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 43/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 44/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 45/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9982\n",
            "Epoch 46/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9982\n",
            "Epoch 47/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 48/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 49/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 50/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 51/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 52/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 53/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9976\n",
            "Epoch 54/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 55/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
            "Epoch 56/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 57/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 58/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9984\n",
            "Epoch 59/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9984\n",
            "Epoch 60/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 61/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9986\n",
            "Epoch 62/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9982\n",
            "Epoch 63/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9993\n",
            "Epoch 64/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 65/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 66/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9987\n",
            "Epoch 67/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9977\n",
            "Epoch 68/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Epoch 69/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 70/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 71/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 72/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9984\n",
            "Epoch 73/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 74/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 75/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 76/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 77/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 78/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 79/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9978\n",
            "Epoch 80/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 81/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9993\n",
            "Epoch 82/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 83/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 84/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0065 - accuracy: 0.9982\n",
            "Epoch 85/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 86/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0029 - accuracy: 0.9993\n",
            "Epoch 87/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9990\n",
            "Epoch 88/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 89/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 90/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 91/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 92/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9990\n",
            "Epoch 93/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9988\n",
            "Epoch 94/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 95/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 96/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 97/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 98/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 99/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9988\n",
            "Epoch 100/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 101/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 102/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 103/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 104/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9986\n",
            "Epoch 105/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 106/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 107/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9990\n",
            "Epoch 108/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 109/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 110/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9988\n",
            "Epoch 111/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 112/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9993\n",
            "Epoch 113/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 114/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 115/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 116/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9996\n",
            "Epoch 117/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 118/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9990\n",
            "Epoch 119/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9994\n",
            "Epoch 120/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 121/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9987\n",
            "Epoch 122/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9991\n",
            "Epoch 123/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 4.5028e-04 - accuracy: 0.9999\n",
            "Epoch 124/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 9.5076e-04 - accuracy: 0.9998\n",
            "Epoch 125/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9994\n",
            "Epoch 126/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 127/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 128/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 129/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9996\n",
            "Epoch 130/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 131/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 132/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 133/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 134/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 135/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 136/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 137/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 138/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 139/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9992\n",
            "Epoch 140/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 141/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 142/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9988\n",
            "Epoch 143/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 144/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 9.9511e-04 - accuracy: 0.9997\n",
            "Epoch 145/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.8456e-05 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 6.4295e-06 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "600/600 [==============================] - 2s 2ms/step - loss: 3.8914e-06 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 3.0549e-06 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 2.4652e-06 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.9939e-06 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.6107e-06 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.2972e-06 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.0330e-06 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 8.1472e-07 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 6.3899e-07 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 4.9719e-07 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 3.8458e-07 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.9444e-07 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.2246e-07 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.6850e-07 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.2755e-07 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 9.5943e-08 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.2449e-08 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.4268e-08 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.0618e-08 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 3.0337e-08 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 2.2775e-08 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 1.7101e-08 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.2936e-08 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 9.8149e-09 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 7.4267e-09 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 5.6863e-09 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 4.3412e-09 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 3.3816e-09 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 2.6504e-09 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.0921e-09 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.6630e-09 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.3093e-09 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.0431e-09 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 8.5036e-10 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 7.1128e-10 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 5.9009e-10 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 4.9869e-10 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 4.0929e-10 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 3.4173e-10 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.9802e-10 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.5431e-10 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.3246e-10 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 2.0266e-10 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.7285e-10 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.5895e-10 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.4901e-10 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.3510e-10 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.2517e-10 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.2914e-10 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 1.0331e-10 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 9.5367e-11 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 9.1394e-11 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 8.7420e-11 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 8.1460e-11 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x21b35c67d90>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=200,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b68ac392-3fbc-4c86-8814-fe8b74f99f29",
      "metadata": {
        "id": "b68ac392-3fbc-4c86-8814-fe8b74f99f29",
        "outputId": "b6c0089a-5819-4c9c-bcaa-bce4473f92d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1983 - accuracy: 0.9843\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.19825313985347748, 0.9843000173568726]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b05ef84-9649-462d-ae41-a5cdee1c0cc5",
      "metadata": {
        "id": "5b05ef84-9649-462d-ae41-a5cdee1c0cc5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c683879c-7973-4110-9366-6375a310dfa7",
      "metadata": {
        "id": "c683879c-7973-4110-9366-6375a310dfa7",
        "outputId": "2b9ccbb9-88eb-41ec-dc9e-b1761e2e2523"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img=cv2.imread(\"d:/hand_digits/3.png\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "gray=gray/255.0\n",
        "probs=model.predict(gray.reshape(1,28,28))\n",
        "np.argmax(probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c060cc5-2c47-4028-b197-327471dce2f0",
      "metadata": {
        "id": "7c060cc5-2c47-4028-b197-327471dce2f0",
        "outputId": "74faaf95-6bb5-4adb-df8b-670271b3f7b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img=cv2.imread(\"d:/hand_digits/7.png\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "gray=gray/255.0\n",
        "probs=model.predict(gray.reshape(1,28,28))\n",
        "np.argmax(probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "040c9450-4944-4a33-b9a8-c21cca098040",
      "metadata": {
        "id": "040c9450-4944-4a33-b9a8-c21cca098040",
        "outputId": "4b1d8693-ec64-44af-c7e6-4c8e0439c3e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfde76d7-bf9a-48f7-ac9d-c4cbe28238d0",
      "metadata": {
        "id": "bfde76d7-bf9a-48f7-ac9d-c4cbe28238d0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647965ee-001b-4742-bb6f-ce5180faef1a",
      "metadata": {
        "id": "647965ee-001b-4742-bb6f-ce5180faef1a",
        "outputId": "32b8f01c-97d2-44d2-9700-66a4b9d83def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 41s 68ms/step - loss: 0.2334 - accuracy: 0.9300\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 38s 63ms/step - loss: 0.0983 - accuracy: 0.9703\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 36s 61ms/step - loss: 0.0671 - accuracy: 0.9789\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 36s 60ms/step - loss: 0.0512 - accuracy: 0.9830\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 36s 60ms/step - loss: 0.0377 - accuracy: 0.9881\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 35s 58ms/step - loss: 0.0306 - accuracy: 0.9900\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 36s 60ms/step - loss: 0.0278 - accuracy: 0.9909\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 37s 62ms/step - loss: 0.0258 - accuracy: 0.9915\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 36s 60ms/step - loss: 0.0239 - accuracy: 0.9920\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 37s 61ms/step - loss: 0.0171 - accuracy: 0.9944\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 35s 58ms/step - loss: 0.0194 - accuracy: 0.9939\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 35s 59ms/step - loss: 0.0186 - accuracy: 0.9939\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 36s 60ms/step - loss: 0.0153 - accuracy: 0.9951\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 38s 63ms/step - loss: 0.0147 - accuracy: 0.9952\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 37s 61ms/step - loss: 0.0173 - accuracy: 0.9943\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 37s 61ms/step - loss: 0.0119 - accuracy: 0.9963\n",
            "Epoch 17/50\n",
            " 52/600 [=>............................] - ETA: 33s - loss: 0.0115 - accuracy: 0.9962"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mC:\\Users\\ADITYA~1\\AppData\\Local\\Temp/ipykernel_6304/2798687806.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,kernel_size=(3,3),input_shape=(28,28,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=50,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8279054c-5b25-499e-bac4-72933eb83f41",
      "metadata": {
        "id": "8279054c-5b25-499e-bac4-72933eb83f41",
        "outputId": "2eb7c412-ec8c-4b3a-b4a2-101604deafea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 13ms/step - loss: 0.1264 - accuracy: 0.9770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.12640230357646942, 0.9769999980926514]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfeba37-b5a2-4c65-8a29-a5d6f03d9409",
      "metadata": {
        "id": "bdfeba37-b5a2-4c65-8a29-a5d6f03d9409",
        "outputId": "e4849d5a-b1dc-4e26-9a01-dc38d15f1269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img=cv2.imread(\"d:/hand_digits/3.png\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "gray=gray/255.0\n",
        "probs=model.predict(gray.reshape(1,28,28))\n",
        "np.argmax(probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2de1a7-0c50-44ab-8e86-79cd1abacbf3",
      "metadata": {
        "id": "fc2de1a7-0c50-44ab-8e86-79cd1abacbf3",
        "outputId": "bf8c6417-b61c-47c0-ac0e-66f13f6b0c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img=cv2.imread(\"d:/hand_digits/7.png\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "gray=gray/255.0\n",
        "probs=model.predict(gray.reshape(1,28,28))\n",
        "np.argmax(probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e540d5-8f96-465f-9230-53d0d8f30be4",
      "metadata": {
        "id": "33e540d5-8f96-465f-9230-53d0d8f30be4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "handwrittendigit.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}