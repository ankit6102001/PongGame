{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit6102001/Python-Machine-learning-Deep-learning/blob/main/Data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e664d105-2cca-45e0-8ed2-73d354518dc0",
      "metadata": {
        "id": "e664d105-2cca-45e0-8ed2-73d354518dc0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a6cc208-2e37-47e6-a3d8-6633f5a2816c",
      "metadata": {
        "id": "6a6cc208-2e37-47e6-a3d8-6633f5a2816c",
        "outputId": "831e1ab7-7dc6-4c26-bf0a-e336cfa1ea6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_gen=ImageDataGenerator(rescale=1/255.0,zoom_range=2,vertical_flip=True,horizontal_flip=True,rotation_range=30)\n",
        "train_itr=train_gen.flow_from_directory(\"d:/dataset/gender_training/train/\",color_mode='grayscale',target_size=(90,90),batch_size=50,class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c49ba4-086b-4416-add3-647a8959d417",
      "metadata": {
        "id": "d5c49ba4-086b-4416-add3-647a8959d417",
        "outputId": "c82d2aa0-455e-4d5c-c2bc-162ee7608920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'female': 0, 'male': 1}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_itr.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b3825a-c6db-4dac-ada8-8a3d33ed41d6",
      "metadata": {
        "id": "41b3825a-c6db-4dac-ada8-8a3d33ed41d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81989b16-24b2-4be9-b819-c820b40b3b66",
      "metadata": {
        "id": "81989b16-24b2-4be9-b819-c820b40b3b66",
        "outputId": "601e6205-c658-45b7-8830-c0b75d54baab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "6/6 [==============================] - 3s 363ms/step - loss: 0.7525 - accuracy: 0.4867\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 0.6880 - accuracy: 0.5367\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 2s 362ms/step - loss: 0.6866 - accuracy: 0.5500\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 2s 365ms/step - loss: 0.6718 - accuracy: 0.6133\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 2s 365ms/step - loss: 0.6321 - accuracy: 0.6267\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 2s 366ms/step - loss: 0.6369 - accuracy: 0.6367\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 2s 380ms/step - loss: 0.6052 - accuracy: 0.6333\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 3s 461ms/step - loss: 0.5382 - accuracy: 0.7300\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 2s 370ms/step - loss: 0.5575 - accuracy: 0.6633\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 2s 378ms/step - loss: 0.5335 - accuracy: 0.7167\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 0.4832 - accuracy: 0.7367\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 2s 390ms/step - loss: 0.5906 - accuracy: 0.6433\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 3s 434ms/step - loss: 0.5213 - accuracy: 0.7467\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 2s 393ms/step - loss: 0.5670 - accuracy: 0.6967\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 2s 368ms/step - loss: 0.5341 - accuracy: 0.6867\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 3s 418ms/step - loss: 0.5730 - accuracy: 0.6833\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 2s 365ms/step - loss: 0.5145 - accuracy: 0.7400\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 2s 371ms/step - loss: 0.5065 - accuracy: 0.7433\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 2s 370ms/step - loss: 0.4924 - accuracy: 0.7267\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 2s 373ms/step - loss: 0.4634 - accuracy: 0.7667\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 2s 406ms/step - loss: 0.4791 - accuracy: 0.7533\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 3s 373ms/step - loss: 0.5427 - accuracy: 0.7167\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 2s 371ms/step - loss: 0.4966 - accuracy: 0.7133\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 2s 371ms/step - loss: 0.5380 - accuracy: 0.7067\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 2s 376ms/step - loss: 0.4824 - accuracy: 0.7500\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 2s 364ms/step - loss: 0.4546 - accuracy: 0.7767\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 2s 409ms/step - loss: 0.4841 - accuracy: 0.7267\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 2s 368ms/step - loss: 0.4845 - accuracy: 0.7400\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 2s 366ms/step - loss: 0.4624 - accuracy: 0.7700\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 2s 370ms/step - loss: 0.4500 - accuracy: 0.7800\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 2s 364ms/step - loss: 0.4565 - accuracy: 0.7667\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 2s 379ms/step - loss: 0.4877 - accuracy: 0.8067\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 3s 421ms/step - loss: 0.4892 - accuracy: 0.7533\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 0.4574 - accuracy: 0.7733\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 2s 363ms/step - loss: 0.4141 - accuracy: 0.7833\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 2s 367ms/step - loss: 0.4005 - accuracy: 0.8367\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 2s 361ms/step - loss: 0.4506 - accuracy: 0.7833\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 2s 366ms/step - loss: 0.4601 - accuracy: 0.7800\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 2s 362ms/step - loss: 0.4645 - accuracy: 0.7767\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 2s 371ms/step - loss: 0.4811 - accuracy: 0.7500\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2b91ccb00a0>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,(3,3),activation='relu',input_shape=(90,90,1)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(train_itr,epochs=40,steps_per_epoch=300//50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa0448b-7b76-4c2a-8e49-678b4873ecda",
      "metadata": {
        "id": "baa0448b-7b76-4c2a-8e49-678b4873ecda",
        "outputId": "dae920c4-8990-491f-eec6-4b70e132468b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_gen=ImageDataGenerator(rescale=1/255.0,zoom_range=2,vertical_flip=True,horizontal_flip=True,rotation_range=30)\n",
        "test_itr=train_gen.flow_from_directory(\"d:/dataset/gender_training/test/\",color_mode='grayscale',target_size=(90,90),batch_size=50,class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c2c4e4c-2270-4431-8c2c-f3ed86d8c433",
      "metadata": {
        "id": "0c2c4e4c-2270-4431-8c2c-f3ed86d8c433",
        "outputId": "0b104232-53d7-4ca0-ac9f-3e68fa298800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4469 - accuracy: 0.7667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.44685590267181396, 0.7666666507720947]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_itr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a81721-d57d-4b4e-9e4e-babcd61aac76",
      "metadata": {
        "id": "53a81721-d57d-4b4e-9e4e-babcd61aac76",
        "outputId": "2f3c1648-e724-402c-ec1d-a11a77d85ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "img=load_img(\"d:/images/cricketers/sachin.jpg\",color_mode='grayscale',target_size=(90,90))\n",
        "np_img=img_to_array(img)\n",
        "#print(np_img.shape)\n",
        "#print(np_img.reshape(1,90,90,1).shape)\n",
        "print(model.predict(np_img.reshape(1,90,90,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01576ec8-97a9-4268-b724-b49818a4ab6b",
      "metadata": {
        "id": "01576ec8-97a9-4268-b724-b49818a4ab6b",
        "outputId": "c0c026c3-e112-4d15-bbcb-955e793a5e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "img=load_img(\"d:/images/players/lata.jpg\",color_mode='grayscale',target_size=(90,90))\n",
        "np_img=img_to_array(img)\n",
        "#print(np_img.shape)\n",
        "#print(np_img.reshape(1,90,90,1).shape)\n",
        "print(model.predict(np_img.reshape(1,90,90,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bdf602-f4f8-48b6-8c13-8d2ab594018a",
      "metadata": {
        "id": "d3bdf602-f4f8-48b6-8c13-8d2ab594018a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Data_augmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}